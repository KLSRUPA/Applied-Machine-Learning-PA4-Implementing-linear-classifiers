{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wcp-vatuBdM"
      },
      "source": [
        "**Name: LAKSHMI SRI RUPA KURUKURI**\n",
        "\n",
        "**Group: 09**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ij_Uc-bvJH4"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "iA3Ofxl0tsEK"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import Normalizer, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
        "import random\n",
        "import warnings\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from scipy.linalg.blas import ddot, daxpy, dscal\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.svm import LinearSVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Exercise Question`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.5\n"
          ]
        }
      ],
      "source": [
        "X1 = [{'city':'Gothenburg', 'month':'July'},\n",
        "      {'city':'Gothenburg', 'month':'December'},\n",
        "      {'city':'Paris', 'month':'July'},\n",
        "      {'city':'Paris', 'month':'December'}]\n",
        "Y1 = ['rain', 'rain', 'sun', 'rain']\n",
        "\n",
        "X2 = [{'city':'Sydney', 'month':'July'},\n",
        "      {'city':'Sydney', 'month':'December'},\n",
        "      {'city':'Paris', 'month':'July'},\n",
        "      {'city':'Paris', 'month':'December'}]\n",
        "Y2 = ['rain', 'sun', 'sun', 'rain']\n",
        "\n",
        "classifier1 = make_pipeline(DictVectorizer(), Perceptron(max_iter=10))\n",
        "classifier1.fit(X1, Y1)\n",
        "guesses1 = classifier1.predict(X1)\n",
        "print(accuracy_score(Y1, guesses1))\n",
        "\n",
        "classifier2 = make_pipeline(DictVectorizer(), Perceptron(max_iter=10))\n",
        "#classifier2 = make_pipeline(DictVectorizer(), LinearSVC())\n",
        "classifier2.fit(X2, Y2)\n",
        "guesses2 = classifier2.predict(X2)\n",
        "print(accuracy_score(Y2, guesses2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. `Why could the classifier \"memorize\" the training data in the first case, but not in the second case?`\n",
        "\n",
        "    In the first training set, the city Gothenburg always has the result as rain which is clear and simple. This simple relationship between the data always allows the perceptron to easily memorize the training data. In the second training set, the weather depends on both the city and monht, which is a complex type of relationship and is not linear, which makes the algorithm to not memorize the relations easily.\n",
        "\n",
        "2. `Why can't we improve the classifier performance by switching to a LinearSVC?`\n",
        "\n",
        "    Switching to a LinearSVC model does not imporve the accuracy because just like perceptron, LinearSVC is also a linear Classifier. As mentioned in the previous answer, the issue with the second data set is the non-linear relationship between variables or features and the output. Therefore, as both the models are constrained to linearity, they cannot accurately catch non-linear patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAV2KHdEuoty"
      },
      "source": [
        "\n",
        "\n",
        "1.   A new class named \"PerceptronTransformer()\" is created transform output of the perceptron class to a binary matrix.\n",
        "2.   Another class named pegasos_calssifier() is created using the pseudocode given in the pegasos resaerch work.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "xG1RBfzrpyc4"
      },
      "outputs": [],
      "source": [
        "\"\"\"This file shows a couple of implementations of the perceptron learning\n",
        "algorithm. It is based on the code from Lecture 3, but using the slightly\n",
        "more compact perceptron formulation that we saw in Lecture 6.\n",
        "\n",
        "There are two versions: Perceptron, which uses normal NumPy vectors and\n",
        "matrices, and SparsePerceptron, which uses sparse vectors and matrices.\n",
        "The latter may be faster when we have high-dimensional feature representations\n",
        "with a lot of zeros, such as when we are using a \"bag of words\" representation\n",
        "of documents.\n",
        "\"\"\"\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class LinearClassifier(BaseEstimator):\n",
        "    \"\"\"\n",
        "    General class for binary linear classifiers. Implements the predict\n",
        "    function, which is the same for all binary linear classifiers. There are\n",
        "    also two utility functions.\n",
        "    \"\"\"\n",
        "\n",
        "    def decision_function(self, X):\n",
        "        \"\"\"\n",
        "        Computes the decision function for the inputs X. The inputs are assumed to be\n",
        "        stored in a matrix, where each row contains the features for one\n",
        "        instance.\n",
        "        \"\"\"\n",
        "        return X.dot(self.w)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predicts the outputs for the inputs X. The inputs are assumed to be\n",
        "        stored in a matrix, where each row contains the features for one\n",
        "        instance.\n",
        "        \"\"\"\n",
        "\n",
        "        # First compute the output scores\n",
        "        scores = self.decision_function(X)\n",
        "\n",
        "        # Select the positive or negative class label, depending on whether\n",
        "        # the score was positive or negative.\n",
        "        out = np.select([scores >= 0.0, scores < 0.0],\n",
        "                        [self.positive_class,\n",
        "                         self.negative_class])\n",
        "        return out\n",
        "\n",
        "    def find_classes(self, Y):\n",
        "        \"\"\"\n",
        "        Finds the set of output classes in the output part Y of the training set.\n",
        "        If there are exactly two classes, one of them is associated to positive\n",
        "        classifier scores, the other one to negative scores. If the number of\n",
        "        classes is not 2, an error is raised.\n",
        "        \"\"\"\n",
        "        classes = sorted(set(Y))\n",
        "        if len(classes) != 2:\n",
        "            raise Exception(\"this does not seem to be a 2-class problem\")\n",
        "        self.positive_class = classes[1]\n",
        "        self.negative_class = classes[0]\n",
        "\n",
        "    def encode_outputs(self, Y):\n",
        "        \"\"\"\n",
        "        A helper function that converts all outputs to +1 or -1.\n",
        "        \"\"\"\n",
        "        return np.array([1 if y == self.positive_class else -1 for y in Y])\n",
        "\n",
        "\n",
        "class Perceptron(LinearClassifier):\n",
        "    \"\"\"\n",
        "    A straightforward implementation of the perceptron learning algorithm.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_iter=20):\n",
        "        \"\"\"\n",
        "        The constructor can optionally take a parameter n_iter specifying how\n",
        "        many times we want to iterate through the training set.\n",
        "        \"\"\"\n",
        "        self.n_iter = n_iter\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        \"\"\"\n",
        "        Train a linear classifier using the perceptron learning algorithm.\n",
        "        \"\"\"\n",
        "\n",
        "        # First determine which output class will be associated with positive\n",
        "        # and negative scores, respectively.\n",
        "        self.find_classes(Y)\n",
        "\n",
        "        # Convert all outputs to +1 (for the positive class) or -1 (negative).\n",
        "        Ye = self.encode_outputs(Y)\n",
        "\n",
        "        # If necessary, convert the sparse matrix returned by a vectorizer\n",
        "        # into a normal NumPy matrix.\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            X = X.toarray()\n",
        "\n",
        "        # Initialize the weight vector to all zeros.\n",
        "        n_features = X.shape[1]\n",
        "        self.w = np.zeros(n_features)\n",
        "\n",
        "        # Perceptron algorithm:\n",
        "        for i in range(self.n_iter):\n",
        "            for x, y in zip(X, Ye):\n",
        "\n",
        "                # Compute the output score for this instance.\n",
        "                score = x.dot(self.w)\n",
        "\n",
        "                # If there was an error, update the weights.\n",
        "                if y*score <= 0:\n",
        "                    self.w += y*x\n",
        "\n",
        "class PerceptronTransformer(LinearClassifier):\n",
        "    \"\"\"\n",
        "    A custom class to transform output of the perceptron class to a binary matrix.\n",
        "\"\"\"\n",
        "    def __init__(self, perceptron):\n",
        "        self.perceptron = perceptron\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.perceptron.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Predict class labels\n",
        "        predictions = self.perceptron.predict(X)\n",
        "        predictions_numerical = np.where(predictions == 'positive', 1, -1)\n",
        "        # Return predictions as binary matrix (1 for positive, 0 for negative)\n",
        "        return np.array(predictions_numerical.astype(int))\n",
        "\n",
        "class pegasos_classifier:\n",
        "  \"\"\"\n",
        "  Pegasos algorithm for training a Support Vector Classifier (SVC).\n",
        "  \"\"\"\n",
        "  def __init__(self, eta=0.01, lambdaa=0.01, iterations=100):\n",
        "    self.eta = eta  # Learning rate\n",
        "    self.lambdaa = lambdaa  # Regularization parameter\n",
        "    self.iterations = iterations  # Maximum number of iterations\n",
        "    self.w = None  # Weight vector\n",
        "\n",
        "\n",
        "  # Function to use the fit() method for the pegosos_classifier\n",
        "  def fit(self, X, y):\n",
        "    \"\"\"\n",
        "    Trains the Pegasos SVC model on the given data (X, y).\n",
        "\n",
        "    Args:\n",
        "      X: A numpy array of shape (n_samples, n_features) representing the training data.\n",
        "      y: A numpy array of shape (n_samples,) representing the labels (either +1 or -1).\n",
        "    \"\"\"\n",
        "    X = np.array(X)\n",
        "    if len(X.shape) < 2:\n",
        "            X = np.atleast_2d(X).T\n",
        "    n_samples, features = X.shape\n",
        "    self.w = np.zeros(features)\n",
        "\n",
        "    for _ in range(self.iterations):\n",
        "      for i in range(n_samples):\n",
        "        Xi = X[i]\n",
        "        Yi = y[i]\n",
        "\n",
        "        Xi = Xi.astype(np.float64)\n",
        "        if Yi * np.dot(Xi, self.w) < 1:\n",
        "\n",
        "            self.w = (1 - self.eta * self.lambdaa) * self.w + self.eta * Yi * Xi\n",
        "        else:\n",
        "            self.w = (1 - self.eta * self.lambdaa) * self.w\n",
        "\n",
        "\n",
        "  # Function to use the predict() method for the pegosos_classifier\n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Predicts the labels for the given data (X).\n",
        "\n",
        "    Args:\n",
        "      X: A numpy array of shape (n_samples, n_features) representing the data to predict.\n",
        "\n",
        "    Returns:\n",
        "      A numpy array of shape (n_samples,) containing the predicted labels (+1 or -1).\n",
        "    \"\"\"\n",
        "    if len(X.shape)<2:\n",
        "        X = np.atleast_2d(X).T\n",
        "    return np.sign(np.dot(X, self.w))\n",
        "\n",
        "\n",
        "  # Function for hpper-parameter tuning.\n",
        "  def set_params(self, **params):\n",
        "    \"\"\"\n",
        "    Set hyperparameters of the PegasosSVC model.\n",
        "    \"\"\"\n",
        "    for key, value in params.items():\n",
        "      setattr(self, key, value)\n",
        "    return self"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to read data (remains unchanged)\n",
        "def read_data(corpus_file):\n",
        "    X = []\n",
        "    Y = []\n",
        "    with open(corpus_file, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            _, y, _, x = line.split(maxsplit=3)\n",
        "            X.append(x.strip())\n",
        "            Y.append(y)\n",
        "    return X, Y\n",
        "\n",
        "X,Y = read_data('data/all_sentiment_shuffled.txt')\n",
        "\n",
        "Xtrain,Xtest,Ytrain,Ytest = train_test_split(X,Y,test_size=0.1,random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementing `preceptron`. Note that this is the perceptron model given in the `aml_perceptron`, not the `sklearn's perceptron`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 5.96 sec.\n",
            "Accuracy: 0.7953.\n"
          ]
        }
      ],
      "source": [
        "piplineperceptron = make_pipeline(\n",
        "    TfidfVectorizer(),\n",
        "    SelectKBest(k=10000),\n",
        "    Normalizer(),\n",
        "    Perceptron()\n",
        ")\n",
        "\n",
        "t0 = time.time()\n",
        "piplineperceptron.fit(Xtrain,Ytrain)\n",
        "t1 = time.time()\n",
        "print('Training time: {:.2f} sec.'.format(t1-t0))\n",
        "\n",
        "Yguess = piplineperceptron.predict(Xtest)\n",
        "print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementation of Pegasos algorithm with a `SVC` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 1.53 sec.\n",
            "Accuracy: 0.7978.\n"
          ]
        }
      ],
      "source": [
        "class PegasosSVC(LinearClassifier):\n",
        "\n",
        "    def __init__(self, n_iter = 20, regularisation = 1):\n",
        "        if not isinstance(n_iter, int):\n",
        "            raise TypeError('n_iter must be an integer.')\n",
        "        self.n_iter = n_iter\n",
        "        self.regularisation = regularisation\n",
        "    \n",
        "    def fit(self, x,y):\n",
        "        self.find_classes(y)\n",
        "        Ye = self.encode_outputs(y)\n",
        "        if not isinstance(x, np.ndarray):\n",
        "            x = x.toarray()\n",
        "        \n",
        "        size_x, n_features = x.shape[0],x.shape[1]\n",
        "        self.w = np.zeros(n_features)\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            r = np.random.choice(size_x,1)[0]\n",
        "\n",
        "            learning_rate = 1.0/ (self.regularisation*(i+1))\n",
        "\n",
        "            X,Y = x[r], Ye[r]\n",
        "            score = self.w.dot(X)\n",
        "\n",
        "            if Y*score<1:\n",
        "                self.w = (1 - learning_rate*self.regularisation)*self.w + learning_rate*Y*X\n",
        "            else:\n",
        "                self.w = (1 - learning_rate*self.regularisation)*self.w\n",
        "\n",
        "piplinePegososSVC = make_pipeline(\n",
        "    TfidfVectorizer(),\n",
        "    SelectKBest(k=1000),\n",
        "    Normalizer(),\n",
        "    PegasosSVC(n_iter=10000, regularisation=1.0/len(Xtrain)*10)\n",
        ")\n",
        "\n",
        "t0 = time.time()\n",
        "piplinePegososSVC.fit(Xtrain, Ytrain)\n",
        "t1 = time.time()\n",
        "print('Training time: {:.2f} sec.'.format(t1-t0))\n",
        "\n",
        "# Evaluate on the test set.\n",
        "Yguess = piplinePegososSVC.predict(Xtest)\n",
        "print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementation of Pegasos algorithm with a `Logistic regression` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 1.39 sec.\n",
            "Accuracy: 0.7643.\n"
          ]
        }
      ],
      "source": [
        "class PegasosLR(LinearClassifier):\n",
        "\n",
        "    def __init__(self, n_iter=20,reg_lambda=1):\n",
        "        if not isinstance(n_iter, int):\n",
        "            raise TypeError('n_iter must be an integer.')\n",
        "        self.n_iter = n_iter\n",
        "        self.reg_lambda = reg_lambda\n",
        "        # self.regularisation = regularisation\n",
        "    \n",
        "    def fit(self,X,Y):\n",
        "        self.find_classes(Y)\n",
        "        Ye = self.encode_outputs(Y)\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            X = X.toarray()\n",
        "        \n",
        "        size_X, n_features = X.shape[0], X.shape[1]\n",
        "        self.w = np.zeros(n_features)\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            k = np.random.choice(size_X,1)[0]\n",
        "            learning_rate = 1.0 / (self.reg_lambda*(i+1))\n",
        "\n",
        "            x,y = X[k], Ye[k]\n",
        "\n",
        "            score = x.dot(self.w)\n",
        "\n",
        "            self.w = (1 - learning_rate*self.reg_lambda)*self.w + x*learning_rate*(y/(1+1/(1+np.exp(-y*score))))\n",
        "\n",
        "piplinePegososLR = make_pipeline(\n",
        "    TfidfVectorizer(),\n",
        "    SelectKBest(k=1000),\n",
        "    Normalizer(),\n",
        "    PegasosLR(n_iter=10000, reg_lambda=1.0/len(Xtrain)*10)\n",
        ")\n",
        "\n",
        "t0 = time.time()\n",
        "piplinePegososLR.fit(Xtrain, Ytrain)\n",
        "t1 = time.time()\n",
        "print('Training time: {:.2f} sec.'.format(t1-t0))\n",
        "\n",
        "# Evaluate on the test set.\n",
        "Yguess = piplinePegososLR.predict(Xtest)\n",
        "print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us implement `BLAS` as mentioned in the optional tasks to decrease the time and improve the accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training time: 1.55 sec.\n",
            "Accuracy: 0.7995.\n"
          ]
        }
      ],
      "source": [
        "class PegasosSVC_optional(LinearClassifier):\n",
        "    def __init__(self, n_iter = 20, reg_lambda=1):\n",
        "        if not isinstance(n_iter, int):\n",
        "            raise TypeError('n_iter should be an integer.')\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.reg_lambda = reg_lambda\n",
        "\n",
        "    def fit(self,X,Y):\n",
        "        self.find_classes(Y)\n",
        "        Ye = self.encode_outputs(Y)\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            X = X.toarray() \n",
        "\n",
        "        size_x , n_features = X.shape[0], X.shape[1]\n",
        "        self.w = np.zeros(n_features)\n",
        "\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "\n",
        "            k = np.random.choice(size_x,1)[0]\n",
        "\n",
        "            eta = 1.0 / (self.reg_lambda*(i+1))\n",
        "\n",
        "            x,y = X[k], Ye[k]\n",
        "\n",
        "            score = ddot(self.w,x)\n",
        "\n",
        "            if y*score < 1:\n",
        "                dscal(1 - eta*self.reg_lambda,self.w)\n",
        "                daxpy(y*x, self.w, a = eta)\n",
        "            else:\n",
        "                dscal(1 - eta*self.reg_lambda,self.w)\n",
        "\n",
        "\n",
        "pipelinePegasosSVC_optional = make_pipeline(\n",
        "    TfidfVectorizer(),\n",
        "    SelectKBest(k=1000),\n",
        "    Normalizer(),\n",
        "    PegasosSVC_optional(n_iter=10000, reg_lambda=1.0/len(Xtrain)*10)\n",
        ")\n",
        "\n",
        "t0 = time.time()\n",
        "pipelinePegasosSVC_optional.fit(Xtrain, Ytrain)\n",
        "t1 = time.time()\n",
        "print('Training time: {:.2f} sec.'.format(t1-t0))\n",
        "\n",
        "Yguess = pipelinePegasosSVC_optional.predict(Xtest)\n",
        "print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, after implementing `BLAS` on the `PegasosSVC`, we have decreased the time by around `250ms`. Using NumPy arrays might be the reason for optimization."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
